{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "18ZeXF3jwRT3IxajfiVJGnIuGseqzEgej",
      "authorship_tag": "ABX9TyP4OCEeAEgq0t6xC7g23cOo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "142a9dd335144f9e9133b4fac3b1876d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc1a78c083f1417880b6faaaab75e43f",
              "IPY_MODEL_9e6a7bd9070c4aa99b5f36081356ec8d",
              "IPY_MODEL_951aea483a684901a7a695ac029ad87a"
            ],
            "layout": "IPY_MODEL_13deb3380e4247c89c4f4c04015da017"
          }
        },
        "fc1a78c083f1417880b6faaaab75e43f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ccbedfabd77428aa37bbb5b87de9683",
            "placeholder": "​",
            "style": "IPY_MODEL_50da6548fd724689aee989f5259a662e",
            "value": "100%"
          }
        },
        "9e6a7bd9070c4aa99b5f36081356ec8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1b1663e2fa648dc95013a6b9b8ca355",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_21bc14f3e8ad4dab8fa2053d4d94de23",
            "value": 3
          }
        },
        "951aea483a684901a7a695ac029ad87a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04f4b8b650744caabc01ee21d5b855e3",
            "placeholder": "​",
            "style": "IPY_MODEL_a96139db6c2c404ba0521eef9f009788",
            "value": " 3/3 [00:02&lt;00:00,  1.61it/s]"
          }
        },
        "13deb3380e4247c89c4f4c04015da017": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ccbedfabd77428aa37bbb5b87de9683": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50da6548fd724689aee989f5259a662e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1b1663e2fa648dc95013a6b9b8ca355": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21bc14f3e8ad4dab8fa2053d4d94de23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "04f4b8b650744caabc01ee21d5b855e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a96139db6c2c404ba0521eef9f009788": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/timob0/rag/blob/main/RAGFP_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load required libraries"
      ],
      "metadata": {
        "id": "ef-cz4rmNBh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install chromadb tqdm fireworks-ai python-dotenv pandas\n",
        "!pip install sentence-transformers\n",
        "\n",
        "import fireworks.client\n",
        "import os\n",
        "import dotenv\n",
        "import chromadb\n",
        "import json\n",
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "import random\n",
        "from google.colab import userdata\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "lG7oQH6DMwN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve Fireworks AI API key\n",
        "dotenv.load_dotenv()\n",
        "fireworks.client.api_key = userdata.get('FW_API_KEY')\n",
        "\n",
        "# Mount Google Drive with the RFP database\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!ls \"/content/drive/My Drive/Colab Notebooks\""
      ],
      "metadata": {
        "id": "V_3CVd7-NVvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A function to get completions from the fireworks LLM"
      ],
      "metadata": {
        "id": "Ls4MKbOAOBGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt, model=None, max_tokens=50):\n",
        "\n",
        "    fw_model_dir = \"accounts/fireworks/models/\"\n",
        "\n",
        "    if model is None:\n",
        "        model = fw_model_dir + \"llama-v3p1-8b-instruct\"\n",
        "    else:\n",
        "        model = fw_model_dir + model\n",
        "\n",
        "    completion = fireworks.client.Completion.create(\n",
        "        model=model,\n",
        "        prompt=prompt,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=0\n",
        "    )\n",
        "\n",
        "    return completion.choices[0].text"
      ],
      "metadata": {
        "id": "l4TOAq_PN_kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test connectivity to the mistral LLM"
      ],
      "metadata": {
        "id": "HsTXsIVBgHMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mistral_llm = \"mixtral-8x7b-instruct\"\n",
        "\n",
        "get_completion(\"[INST]Tell me 2 jokes[/INST]\", model=mistral_llm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ugp1-R3eQMRf",
        "outputId": "7f3d262a-0f37-4f5c-ddd1-2cbf1a641e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Sure, here are two jokes for you:\\n\\n1. Why don't scientists trust atoms?\\n\\nBecause they make up everything!\\n\\n1. Why did the scarecrow win an award?\\n\\nBecause he was outstanding\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usecase: Read a database with RFP Questions and Answers to augment the text generation using the LLM. See: retrieval augmented generation.\n"
      ],
      "metadata": {
        "id": "2Uc9wKU6R5EL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset from google drive and convert to dataframe\n",
        "# dataset contains column names\n",
        "rfp_file = pd.read_csv('/content/drive/My Drive/Colab Notebooks/rfp_data.csv', header=0, delimiter=\";\")\n",
        "\n",
        "# remove rows with empty titles or descriptions\n",
        "rfp_qa = rfp_file.dropna(subset=[\"Question\", \"Answer\"])\n",
        "rfp_qa.head()"
      ],
      "metadata": {
        "id": "4xzDv7_NRs3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert dataframe to list of dicts with Question and Answer columns only\n",
        "rfp_qa_dict = rfp_qa.to_dict(orient=\"records\")\n",
        "rfp_qa_dict[0]"
      ],
      "metadata": {
        "id": "BKOdXNWdSDBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Chroma DB as a vector database to store word embeddings."
      ],
      "metadata": {
        "id": "5_xx29YSg6mB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "class MyEmbeddingFunction(EmbeddingFunction):\n",
        "    def __call__(self, input: Documents) -> Embeddings:\n",
        "        batch_embeddings = embedding_model.encode(input)\n",
        "        return batch_embeddings.tolist()\n",
        "\n",
        "embed_fn = MyEmbeddingFunction()\n",
        "\n",
        "# Initialize the chromadb directory, and client.\n",
        "client = chromadb.PersistentClient(path=\"./chromadb\")\n",
        "\n",
        "# create collection\n",
        "collection = client.get_or_create_collection(\n",
        "    name=f\"rfp-materials-2024\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHyPdw3MSLzo",
        "outputId": "57dbb836-2549-4e9d-d7ef-e6ebfc2509b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate embeddings, and index titles in batches\n",
        "batch_size = 50\n",
        "\n",
        "# loop through batches and generated + store embeddings\n",
        "for i in tqdm(range(0, len(rfp_qa_dict), batch_size)):\n",
        "\n",
        "    i_end = min(i + batch_size, len(rfp_qa_dict))\n",
        "    batch = rfp_qa_dict[i : i + batch_size]\n",
        "\n",
        "    # Replace empty strings (shouldn't happen)\n",
        "    batch_titles = [str(paper[\"Question\"]) if str(paper[\"Question\"]) != \"\" else \"No Question\" for paper in batch]\n",
        "    batch_answers = [str(paper[\"Answer\"]) if str(paper[\"Answer\"]) != \"\" else \"No Answer\" for paper in batch]\n",
        "    batch_ids = [str(sum(ord(c) + random.randint(1, 10000) for c in paper[\"Question\"])) for paper in batch]\n",
        "    #batch_metadata = [dict(url=paper[\"PaperURL\"],\n",
        "    #                       abstract=paper['Abstract'])\n",
        "    #                       for paper in batch]\n",
        "\n",
        "    # generate embeddings\n",
        "    batch_embeddings = embedding_model.encode(batch_titles)\n",
        "\n",
        "    # upsert to chromadb\n",
        "    collection.upsert(\n",
        "        ids=batch_ids,\n",
        "    #    metadatas=batch_metadata,\n",
        "    #    documents=batch_titles,\n",
        "        documents=batch_answers,\n",
        "        embeddings=batch_embeddings.tolist(),\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "142a9dd335144f9e9133b4fac3b1876d",
            "fc1a78c083f1417880b6faaaab75e43f",
            "9e6a7bd9070c4aa99b5f36081356ec8d",
            "951aea483a684901a7a695ac029ad87a",
            "13deb3380e4247c89c4f4c04015da017",
            "9ccbedfabd77428aa37bbb5b87de9683",
            "50da6548fd724689aee989f5259a662e",
            "c1b1663e2fa648dc95013a6b9b8ca355",
            "21bc14f3e8ad4dab8fa2053d4d94de23",
            "04f4b8b650744caabc01ee21d5b855e3",
            "a96139db6c2c404ba0521eef9f009788"
          ]
        },
        "id": "0hXkQQBWSgpH",
        "outputId": "60303075-7994-4e77-df1d-1d57d498598d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "142a9dd335144f9e9133b4fac3b1876d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the text retriever, this will retrieve output based on the data found in the vector database."
      ],
      "metadata": {
        "id": "eRPdWwvuS9Mg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "collection = client.get_or_create_collection(\n",
        "    name=f\"rfp-materials-2024\",\n",
        "    embedding_function=embed_fn\n",
        ")\n",
        "\n",
        "retriever_results = collection.query(\n",
        "    query_texts=[\"What are ESG factors?\"],\n",
        "    n_results=2,\n",
        ")\n",
        "\n",
        "print(retriever_results[\"documents\"])"
      ],
      "metadata": {
        "id": "2rSPeBEJS3-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# user query\n",
        "user_query = \"How is ESG integrated?\"\n",
        "\n",
        "# query for user query\n",
        "results = collection.query(\n",
        "    query_texts=[user_query],\n",
        "    n_results=3,\n",
        ")\n",
        "\n",
        "# concatenate titles into a single string\n",
        "answers = '\\n'.join(results['documents'][0])\n",
        "\n",
        "prompt_template = f'''[INST]\n",
        "\n",
        "Your main task is to generate RFP_TEXT by summarizing the RFP_ANSWERS.\n",
        "\n",
        "You should mimic a style similar to the one in the QUESTION.\n",
        "\n",
        "QUESTION: {user_query}\n",
        "\n",
        "RFP_ANSWERS: {answers}\n",
        "\n",
        "RFP_TEXT:\n",
        "\n",
        "[/INST]\n",
        "'''\n",
        "\n",
        "model_response = get_completion(prompt_template, model=mistral_llm, max_tokens=500)\n",
        "\n",
        "# Print the suggestions.\n",
        "print(\"Your query\")\n",
        "print(\">>> \", user_query)\n",
        "print(\"***********************\")\n",
        "\n",
        "print(\"Model generated answer:\")\n",
        "print()\n",
        "print(model_response)\n",
        "print(\"***********************\")\n",
        "\n",
        "print(\"Reference answers from RFP database:\")\n",
        "print()\n",
        "print(answers)\n",
        "print(\"***********************\")"
      ],
      "metadata": {
        "id": "utT859zvTPjG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}